{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Programming Module\n",
    "\n",
    "## 1. [Probabilistic Programming background](S14A_Probabilisitc_Programming_Background.ipynb)\n",
    "\n",
    "- Bayes theorem\n",
    "- Probabilistic Programming\n",
    "  - DSL for model construction, inference and evaluation\n",
    "  - Inference Engines\n",
    "  - PyMC3, PyStan and Edward 2\n",
    "- Estimating integrals\n",
    "- Numerical integration (Quadrature)\n",
    "- Curse of dimensionality and concentration of measure\n",
    "- Working with random variables\n",
    "- Monte Carlo simulations\n",
    "- Monte Carlo integration\n",
    "- Drawing pictures\n",
    "\n",
    "## 2. Metropolis, Metropolis-Hastings and Gibbs\n",
    "\n",
    "- Markov Chains\n",
    "- Reversibility\n",
    "- Metropolis\n",
    "- Metropolis-Hastings\n",
    "- Gibbs\n",
    "\n",
    "## 3. HMC and NUTS\n",
    "\n",
    "- Probability and  Physics\n",
    "- Hamiltonian systems\n",
    "- Integrating ODEs\n",
    "- HMC\n",
    "- Tuning with the No U-Turn Sampler (NUTS)\n",
    "- Visualizing HMC\n",
    "\n",
    "## 4. Deterministic inference engines\n",
    "\n",
    "- Grid evaluation\n",
    "- Laplace approximation\n",
    "- Variational inference\n",
    "- Kullback-Leibler divergence and ELBO\n",
    "- Limitations of mean-field approximations\n",
    "\n",
    "## 5. PyMC3 I\n",
    "\n",
    "- Mechanics\n",
    "  - Model\n",
    "  - Inference\n",
    "  - Evaluation\n",
    "- Inference engies in PyMC3\n",
    "- Using `arviz` for visualization\n",
    "- Bernoulli-Binomial model\n",
    "- Linear regression\n",
    "- Robust linear regression\n",
    "- Logistic regression\n",
    "- Poisson regression\n",
    "- The GLM module\n",
    "\n",
    "## 6. PyMC3 II\n",
    "\n",
    "- Change point models\n",
    "- Hierarchical models\n",
    "- Mixture models\n",
    "\n",
    "## 7. PyMC3 III\n",
    "\n",
    "- Non-parametric model concepts\n",
    "- GP models\n",
    "- DP models\n",
    "\n",
    "## 8. TF\n",
    "\n",
    "- The data flow graph and lazy evaluation\n",
    "- Automatic differentiation\n",
    "- Optimization\n",
    "- Models in TF\n",
    "- Models in `keras`\n",
    "\n",
    "## 9. TF Probability\n",
    "\n",
    "- Probability distributions\n",
    "- Basic usage of Edward 2 with coin toss example\n",
    "- Regression with Edward 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
